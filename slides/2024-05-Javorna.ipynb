{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbb23d39-72fc-465e-810f-b8bb83a95d05",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Recent neural network architectures, large language models and image generators\n",
    "\n",
    "\n",
    "## M. Jiřík, I. Gruber, V. Liška"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74b9194-223d-46f9-b6c4-bf14598e3b42",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "# Biological neuron\n",
    "\n",
    "![biological neuron wikipedia](https://upload.wikimedia.org/wikipedia/commons/thumb/1/10/Blausen_0657_MultipolarNeuron.png/1675px-Blausen_0657_MultipolarNeuron.png)\n",
    "\n",
    "By BruceBlaus - Own work, CC BY 3.0, https://commons.wikimedia.org/w/index.php?curid=28761830"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0bdfca-d83f-4df8-9a8e-67dbbe181f90",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# AI Neuron model\n",
    "\n",
    "![biological and artificial neuron](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60d243db4b12f1c8f339e8cb_unnamed.jpg)\n",
    "\n",
    "Pragati Baheti: [Activation Functions in Neural Networks, V7Labs Blog, 2021](https://www.v7labs.com/blog/neural-networks-activation-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f3e40cc-6eee-4402-925a-47029e1d6d86",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# AI Neuron model\n",
    "\n",
    "![biological and artificial neuron](https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60d2424009416f21db643e21_Group%20807.jpg)\n",
    "\n",
    "Pragati Baheti: [Activation Functions in Neural Networks, V7Labs Blog, 2021](https://www.v7labs.com/blog/neural-networks-activation-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508f20f8-65a4-44f0-84a9-c05f6a73c70b",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "skip"
    },
    "tags": []
   },
   "source": [
    "# AI Neuron Model\n",
    "\n",
    "![AI neuron model](https://i0.wp.com/theneuralblog.com/wp-content/uploads/2021/04/neuron.png?resize=768%2C432&ssl=1)\n",
    "\n",
    "By Rabindra Lamsal, [A step by step forward pass and backpropagation example](https://theneuralblog.com/forward-pass-backpropagation-example/), The Neural Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984791a4-88c9-4c7a-9e1d-659ded6af993",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Biological Neuron Activation\n",
    "\n",
    "\n",
    "![biological neuron action potential](https://upload.wikimedia.org/wikipedia/commons/thumb/4/4a/Action_potential.svg/491px-Action_potential.svg.png)\n",
    "\n",
    "Christophe Leterrier: [The Axon Initial Segment: An Updated Viewpoint, Journal of Neuroscience (2018)](https://doi.org/10.1523/JNEUROSCI.1922-17.2018), [Image CC BY-SA 3.0 , via Wikimedia Commons](https://en.wikipedia.org/wiki/File:Action_potential.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bf6b6b-fedb-4a79-b1c2-9a47ba378535",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Artificial Neuron Activation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b90d2-66e2-4c0e-8896-82f4ee169d46",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "![Activation functions](https://miro.medium.com/v2/resize:fit:720/format:webp/1*ZafDv3VUm60Eh10OeJu1vw.png)\n",
    "\n",
    "\n",
    "Image by Shruti Jadon, [Introduction to different activation functions for deep learning, Medium, Augmenting Humanity](https://medium.com/@shrutijadon/survey-on-activation-functions-for-deep-learning-9689331ba092)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9710211a-d8fd-48dd-bc18-7557fd6c1b21",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Neural network example\n",
    "\n",
    "\n",
    "<img src=\"https://datamining.togaware.com/survivor/ann-example.png\" widht=\"100%\">\n",
    "\n",
    "Williams, Graham. [\"Data mining desktop survival guide\"](https://datamining.togaware.com/survivor/Neural_Network.html), Togaware (2006)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a5c84f-6eaf-4dcf-826e-54a9ffbcd410",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Example\n",
    "\n",
    "![](https://i0.wp.com/theneuralblog.com/wp-content/uploads/2021/04/neural-network.png?resize=768%2C432&ssl=1)\n",
    "\n",
    "By Rabindra Lamsal, [A step by step forward pass and backpropagation example](https://theneuralblog.com/forward-pass-backpropagation-example/), The Neural Blog"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406df605-f64d-45c5-a0c2-00f264761845",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "Neural network model\n",
    "\n",
    "* Architecture\n",
    "* Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62370cea-7ffc-4b44-a4eb-046327ae24e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Architectures\n",
    "\n",
    "* Fully connected\n",
    "* Convolutional\n",
    "* Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc294b2-3761-4c1d-9f1c-4d7fc33315d5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "# Fully connected architecture\n",
    "\n",
    "<img src=\"https://assets-global.website-files.com/5d7b77b063a9066d83e1209c/60d242974bcba9f8c670e03e_Group%20806.jpg\" height=\"80%\">\n",
    "\"\"\n",
    "Pragati Baheti: [Activation Functions in Neural Networks, V7Labs Blog, 2021](https://www.v7labs.com/blog/neural-networks-activation-functions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b215df-a715-4422-be86-00a2fe08a185",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Convolution\n",
    "\n",
    "<img class=\"r-stretch\" src=\"https://analyticsindiamag.com/wp-content/uploads/2018/01/conv-full-layer.gif\">\n",
    "\n",
    "by Kishan Maladkar [Overview Of Convolutional Neural Network In Image Classification](https://analyticsindiamag.com/convolutional-neural-network-image-classification-overview/), (2018)\n",
    "\n",
    "Krizhevsky A, Sutskever I, Hinton GE. [Imagenet classification with deep convolutional neural networks](https://proceedings.neurips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf). Advances in Neural Information Processing Systems 2012; 25."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4dd8926-dc01-47a4-8df1-fffc2466357f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Convolutions\n",
    "\n",
    "<img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*42gghIga-ZhE0qRxEH7Wug.png\" width=\"100%\">\n",
    "\n",
    "By Shweta Kadam [CNN Series Part1: How do computers see images?](https://medium.com/analytics-vidhya/cnn-series-part-1-how-do-computers-see-images-32462a0b33ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6b493-df2c-4b1c-a4ff-fab64b814ad6",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Transformer\n",
    "\n",
    "<img src=\"https://jalammar.github.io/images/t/transformer_self-attention_visualization.png\" height=\"80%\">\n",
    "\n",
    "Vaswani, Ashish, et al. [Attention is all you need.](https://proceedings.neurips.cc/paper_files/paper/2017/hash/3f5ee243547dee91fbd053c1c4a845aa-Abstract.html) Advances in neural information processing systems 30 (2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "792f5c4c-ac8d-46e1-938a-e66418f90cbb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Pneumonia classification\n",
    "\n",
    "<img src=\"pneumonia_dataset.png\" >\n",
    "\n",
    "1583 normal images and 4273 Pneumonia images from `kaggle-chest-xray-pneumonia` dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffc78124-d059-4982-96ff-e4ad1c8dd151",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Results\n",
    "\n",
    "\n",
    "* Shallow convolutional architecture\n",
    "  * 1.2M parameters\n",
    "  * Accuracy 0.74\n",
    "* ResNet50 - Convolutional architecture\n",
    "    * 26M parameters\n",
    "    * Accuracy 0.83\n",
    "* ViT - Transformer architecture\n",
    "    * 14M parameters\n",
    "    * Accuracy 0.86"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a25a02-64b3-41fe-8dc6-e9bb99bf02a1",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Recent research directions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6da1302-4f2d-4e00-b605-3821d7c0750a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Image generators\n",
    "\n",
    "![stable diffusion](https://miro.medium.com/v2/resize:fit:1400/0*a6FugiEl0J6768W8)\n",
    "\n",
    "Guodong (Troy) Zhao [How Stable Diffusion works, explained for non-technical people](https://bootcamp.uxdesign.cc/how-stable-diffusion-works-explained-for-non-technical-people-be6aa674fa1d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583bbaa4-8f90-4f9d-b0f5-4e15e886b206",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Make models larger\n",
    "\n",
    " * GPT-2: 1.5 bilion parameters\n",
    " * GPT-3: 175 billion parameters\n",
    " * GPT-4: 1.76 trillion parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5f8944-ce34-45aa-970c-c4dfa4152150",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# GPT-2 Training\n",
    "\n",
    "\n",
    "![](gpt3_dataset.png)\n",
    "\n",
    "* 1.5 bilion parameters\n",
    "\n",
    "\n",
    "\n",
    "Simon O'Regan[GPT-3: Demos, Use-cases, Implications](https://towardsdatascience.com/gpt-3-demos-use-cases-implications-77f86e540dc1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ce8986-a64f-420c-9dd2-24010e2245ec",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "![](nvidia_v100.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd5f630-6889-4a52-8574-b082cdd2550f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "fragment"
    },
    "tags": []
   },
   "source": [
    "cca 355 GPU Years on Tesla V100 = $4.6M"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec4cd56-289d-404c-9776-07eb58f78b56",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Multi-modal models\n",
    "\n",
    " * Combine text, image and speech\n",
    " * BLIP\n",
    " \n",
    "   <img src=\"https://miro.medium.com/v2/resize:fit:720/format:webp/1*oDJjZ436o2aDvqes5zPJCQ.png\" width=\"40%\">\n",
    " * [Introducing GPT-4o](https://www.youtube.com/live/DQacCB9tDaw?si=L0XhVQe0buQ-vJRQ&t=837)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ceffef2-f0b2-4f8f-b0fa-879357e297a2",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Conclusion\n",
    "\n",
    "* Three main architecture designs\n",
    "  * Fully connected\n",
    "  * Convlutional\n",
    "  * Transformers\n",
    "* Architecture depends\n",
    "* Multi-modal is the future"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3990f88a-14f1-46ea-ab25-33e88af5e6b5",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "# Thank you"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b29049-251d-428d-8a3c-9fc8c4cbd8cd",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
